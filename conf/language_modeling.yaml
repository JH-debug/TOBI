# data & model module
pretrained_model: skt/ko-gpt-trinity-1.2B-v0.5 # monologg/koelectra-base-v3-discriminator
batch_size: 2
num_workers: 1
data_type: "grapheme"
train_file: "processed/seq2seq_train.json"
validation_file: "processed/seq2seq_val.json"
test_file: "processed/seq2seq_test.json"

# trainer
accelerator: "auto"
devices: [1]
max_epochs: 200
check_val_every_n_epoch: 1
accumulate_grad_batches: 16
log_every_n_steps: 100
checkpoint_dir: "model_save"
seed: 1234

# wandb logger
project: TOBI
name: LM_kogpt_grapheme

# saved model_path
model_path: "model_save/LM_grapheme_kogpt_epoch=3-val_bleu_score=0.07.ckpt"